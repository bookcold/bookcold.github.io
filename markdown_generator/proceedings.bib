
@inproceedings{yuan_incorporating_2016,
	title = {Incorporating Pre-Training in Long Short-Term Memory Networks for Tweets Classification},
	doi = {10.1109/ICDM.2016.0181},
	abstract = {The paper presents deep learning models for tweets binary classification. Our approach is based on the Long Short-Term Memory ({LSTM}) recurrent neural network and hence expects to be able to capture long-term dependencies among words. We develop two models for tweets classification. The basic model, called {LSTM}-{TC}, takes word embeddings as input, uses the {LSTM} layer to derive semantic tweet representation, and applies logistic regression to predict tweet label. The basic {LSTM}-{TC} model, like other deep learning models, requires a large amount of well-labeled training data to achieve good performance. To address this challenge, we further develop an improved model, called {LSTM}-{TC}*, that incorporates a large amount of weakly-labeled data for classifying tweets. We present two approaches of constructing the weakly-labeled data. One is based on hashtag information and the other is based on the prediction output of some traditional classifier that does not need a large amount of well-labeled training data. Our {LSTM}-{TC}* model first learns tweet representation based on the weakly-labeled data, and then trains the logistic regression classifier based on the small amount of well-labeled data. Experimental results show that: (1) the proposed method can be successfully used for tweets classification and outperform existing state-of-the-art methods, (2) pre-training tweet representation, which utilizes weakly-labeled tweets, can significantly improve the accuracy of tweets classification.},
	eventtitle = {2016 {IEEE} 16th International Conference on Data Mining ({ICDM})},
	pages = {1329--1334},
	booktitle = {2016 {IEEE} 16th International Conference on Data Mining ({ICDM})},
	author = {Yuan, S. and Wu, X. and Xiang, Y.},
	date = {2016-12},
	keywords = {learning (artificial intelligence), Semantics, Training, Twitter, social networking (online), recurrent neural network, Data models, recurrent neural nets, pattern classification, logistic regression, Logistics, regression analysis, Deep learning, deep learning models, hashtag information, Logic gates, logistic regression classifier, long short-term memory networks, long-term dependencies, {LSTM}, {LSTM}-{TC} model, Pre-training, semantic tweet representation, Tagging, tweet label, tweet representation, tweets binary classification, Tweets classification, weakly-labeled data, weakly-labeled tweets, well-labeled training data},
	file = {2016_Incorporating Pre-Training in Long Short-Term Memory Networks for Tweets_Yuan et al.pdf:/home/sy/Zotero/storage/IHSJJYYC/2016_Incorporating Pre-Training in Long Short-Term Memory Networks for Tweets_Yuan et al.pdf:application/pdf;IEEE Xplore Abstract Record:/home/sy/Zotero/storage/IGGUCUCY/7837994.html:text/html}
}

@inproceedings{yuan_knowledge_2015,
	title = {A Knowledge Resources Based Neural Network for Learning Word and Relation Representations},
	doi = {10.1109/HPCC-CSS-ICESS.2015.107},
	abstract = {Using neural networks to train high quality distributed representations of words and multi-relational data has attracted a great attention in recent years. Mapping the words and their relations to low-dimensional continues vector spaces has proved to be useful in natural language processing and information extraction tasks. In this paper, we present a neural network based model that can train word embeddings and relation embeddings taking into account unlabeled text data and knowledge resources jointly. In particular, we use both contexts and definitions of words as neural network inputs to train word embeddings. Based on the word embeddings, we train relation embeddings by defining a proper projecting operation between words. Experiments on various tasks like word similarity and link prediction show that the proposed method can achieve high quality on word and relation representations.},
	eventtitle = {2015 {IEEE} 17th International Conference on High Performance Computing and Communications, 2015 {IEEE} 7th International Symposium on Cyberspace Safety and Security, and 2015 {IEEE} 12th International Conference on Embedded Software and Systems},
	pages = {1731--1736},
	booktitle = {2015 {IEEE} 17th International Conference on High Performance Computing and Communications, 2015 {IEEE} 7th International Symposium on Cyberspace Safety and Security, and 2015 {IEEE} 12th International Conference on Embedded Software and Systems},
	author = {Yuan, S. and Xiang, Y. and Li, M.},
	date = {2015-08},
	keywords = {Context, Context modeling, distributed representations, information extraction, Knowledge based systems, Knowledge engineering, knowledge resource-based neural network, knowledge resources, learning (artificial intelligence), link prediction, low-dimensional data, multirelational data, natural language processing, neural nets, neural network, neural network based model, neural network training, Neural networks, relation embedding training, relation embeddings, relation representation learning, Semantics, text analysis, Training, unlabeled text data, vector spaces, word embedding training, Word embeddings, word mapping, word representation learning, word similarity},
	file = {2015_A Knowledge Resources Based Neural Network for Learning Word and Relation_Yuan et al.pdf:/home/sy/Zotero/storage/KK9DA2NB/2015_A Knowledge Resources Based Neural Network for Learning Word and Relation_Yuan et al.pdf:application/pdf;IEEE Xplore Abstract Record:/home/sy/Zotero/storage/6HUA2VVY/7336421.html:text/html}
}

@inproceedings{yuan_two_2016,
	title = {A Two Phase Deep Learning Model for Identifying Discrimination from Tweets},
	url = {https://doi.org/10.5441/002/edbt.2016.92},
	doi = {10.5441/002/edbt.2016.92},
	pages = {696--697},
	booktitle = {Proceedings of the 19th International Conference on Extending Database Technology, {EDBT} 2016},
	author = {Yuan, Shuhan and Wu, Xintao and Xiang, Yang},
	date = {2016}
}

@inproceedings{xu_differential_2017,
	title = {Differential Privacy Preserving Causal Graph Discovery},
	doi = {10.1109/PAC.2017.24},
	abstract = {Discovering causal relationships by constructing the causal graph provides critical information to researchers and decision makers. Yet releasing causal graphs may risk leakage of individual participant's privacy. It is very underexploited how to enforce differential privacy in causal graph discovery. In this work, we focus on the {PC} algorithm, a classic constraint-based causal graph discovery algorithm, and propose a differentially private {PC} algorithm ({PrivPC}) for categorical data. {PrivPC} adopts the exponential mechanism and significantly reduces the number of edge elimination decisions. Therefore, it incurs much less privacy budget than the naive approaches that add privacy protection at each conditional independence test. For numerical data, we further develop a differentially private causal discovery algorithm ({PrivPC}*). The idea is to add noise once onto the covariance matrix from which partial correlations used for conditional independence test can be derived. Experimental results show that {PrivPC} and {PrivPC}* achieve good utility and robustness for different settings of causal graphs. To our best knowledge, this is the first work on how to enforce differential privacy in constraint-based causal graph discovery.},
	eventtitle = {2017 {IEEE} Symposium on Privacy-Aware Computing ({PAC})},
	pages = {60--71},
	booktitle = {2017 {IEEE} Symposium on Privacy-Aware Computing ({PAC})},
	author = {Xu, D. and Yuan, S. and Wu, X.},
	date = {2017-08},
	keywords = {Electronic mail, belief networks, data mining, data privacy, graph theory, causal graph, Correlation, Markov processes, Data privacy, categorical data, causal graph discovery algorithm, causal relationships, causality, conditional independence test, constraint-based causal graph discovery, covariance matrix, differential privacy, differential privacy preserving causal graph discovery, differentially private causal discovery algorithm, differentially private {PC} algorithm, edge elimination decisions, exponential mechanism, individual participant, {PC} algorithm, Privacy, privacy budget, privacy protection, {PrivPC}, Probability distribution, Skeleton},
	file = {2017_Differential Privacy Preserving Causal Graph Discovery_Xu et al.pdf:/home/sy/Zotero/storage/DB6WFWTT/2017_Differential Privacy Preserving Causal Graph Discovery_Xu et al.pdf:application/pdf;IEEE Xplore Abstract Record:/home/sy/Zotero/storage/E2CI5675/8166616.html:text/html}
}

@inproceedings{yuan_sne:_2017,
	title = {{SNE}: Signed Network Embedding},
	isbn = {978-3-319-57529-2},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SNE}},
	abstract = {Several network embedding models have been developed for unsigned networks. However, these models based on skip-gram cannot be applied to signed networks because they can only deal with one type of link. In this paper, we present our signed network embedding model called {SNE}. Our {SNE} adopts the log-bilinear model, uses node representations of all nodes along a given path, and further incorporates two signed-type vectors to capture the positive or negative relationship of each edge along the path. We conduct two experiments, node classification and link prediction, on both directed and undirected signed networks and compare with four baselines including a matrix factorization method and three state-of-the-art unsigned network embedding models. The experimental results demonstrate the effectiveness of our signed network embedding.},
	pages = {183--195},
	booktitle = {Pacific-Asia conference on knowledge discovery and data mining},
	publisher = {Springer International Publishing},
	author = {Yuan, Shuhan and Wu, Xintao and Xiang, Yang},
	editor = {Kim, Jinho and Shim, Kyuseok and Cao, Longbing and Lee, Jae-Gil and Lin, Xuemin and Moon, Yang-Sae},
	date = {2017},
	langid = {english},
	file = {2017_SNE_Yuan et al.pdf:/home/sy/Zotero/storage/R9EMCA7V/2017_SNE_Yuan et al.pdf:application/pdf}
}

@inproceedings{yuan_spectrum-based_2017,
	location = {New York, {NY}, {USA}},
	title = {Spectrum-based Deep Neural Networks for Fraud Detection},
	isbn = {978-1-4503-4918-5},
	url = {http://doi.acm.org/10.1145/3132847.3133139},
	doi = {10.1145/3132847.3133139},
	series = {{CIKM} '17},
	abstract = {In this paper, we focus on fraud detection on a signed graph with only a small set of labeled training data. We propose a novel framework that combines deep neural networks and spectral graph analysis. In particular, we use the node projection (called as spectral coordinate) in the low dimensional spectral space of the graph's adjacency matrix as the input of deep neural networks. Spectral coordinates in the spectral space capture the most useful topology information of the network. Due to the small dimension of spectral coordinates (compared with the dimension of the adjacency matrix derived from a graph), training deep neural networks becomes feasible. We develop and evaluate two neural networks, deep autoencoder and convolutional neural network, in our fraud detection framework. Experimental results on a real signed graph show that our spectrum based deep neural networks are effective in fraud detection.},
	pages = {2419--2422},
	booktitle = {Proceedings of the 2017 {ACM} on Conference on Information and Knowledge Management},
	publisher = {{ACM}},
	author = {Yuan, Shuhan and Wu, Xintao and Li, Jun and Lu, Aidong},
	urldate = {2019-07-26},
	date = {2017},
	keywords = {deep neural networks, fraud detection, spectrum},
	file = {2017_Spectrum-based Deep Neural Networks for Fraud Detection_Yuan et al.pdf:/home/sy/Zotero/storage/AXTL777Y/2017_Spectrum-based Deep Neural Networks for Fraud Detection_Yuan et al.pdf:application/pdf}
}

@inproceedings{yuan_wikipedia_2017,
	title = {Wikipedia Vandal Early Detection: From User Behavior to User Embedding},
	isbn = {978-3-319-71249-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Wikipedia Vandal Early Detection},
	abstract = {Wikipedia is the largest online encyclopedia that allows anyone to edit articles. In this paper, we propose the use of deep learning to detect vandals based on their edit history. In particular, we develop a multi-source long-short term memory network (M-{LSTM}) to model user behaviors by using a variety of user edit aspects as inputs, including the history of edit reversion information, edit page titles and categories. With M-{LSTM}, we can encode each user into a low dimensional real vector, called user embedding. Meanwhile, as a sequential model, M-{LSTM} updates the user embedding each time after the user commits a new edit. Thus, we can predict whether a user is benign or vandal dynamically based on the up-to-date user embedding. Furthermore, those user embeddings are crucial to discover collaborative vandals. Code and data related to this chapter are available at: https://bitbucket.org/bookcold/vandal\_detection.},
	pages = {832--846},
	booktitle = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	publisher = {Springer International Publishing},
	author = {Yuan, Shuhan and Zheng, Panpan and Wu, Xintao and Xiang, Yang},
	editor = {Ceci, Michelangelo and Hollmén, Jaakko and Todorovski, Ljupčo and Vens, Celine and Džeroski, Sašo},
	date = {2017},
	langid = {english},
	file = {2017_Wikipedia Vandal Early Detection_Yuan et al.pdf:/home/sy/Zotero/storage/NNMYPUIZ/2017_Wikipedia Vandal Early Detection_Yuan et al.pdf:application/pdf}
}

@inproceedings{xu_dpne:_2018,
	title = {{DPNE}: Differentially Private Network Embedding},
	isbn = {978-3-319-93037-4},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{DPNE}},
	abstract = {Learning the low-dimensional representations of the vertices in a network can help users understand the network structure and perform other data mining tasks efficiently. Various network embedding approaches such as {DeepWalk} and {LINE} have been developed recently. However, how to protect the individual privacy in network embedding has not been exploited. It is challenging to achieve high utility as the sensitivity of stochastic gradients in random walks and that of edge sampling are very high, thus incurring high utility loss when applying Laplace mechanism and exponential mechanism to achieve differential privacy. In this paper, we develop a differentially private network embedding method ({DPNE}). In this method, we leverage the recent theoretical findings that network embedding methods such as {DeepWalk} and {LINE} are equivalent to factorization of some matrices derived from the adjacency matrix of the original network and apply objective perturbation on the objective function of matrix factorization. We evaluate the learned representations by our {DPNE} from three different real world datasets on two data mining tasks: vertex classification and link prediction. Experiment results show the effectiveness of {DPNE}. To our best knowledge, this is the first work on how to preserve differential privacy in network embedding.},
	pages = {235--246},
	booktitle = {Advances in Knowledge Discovery and Data Mining},
	publisher = {Springer International Publishing},
	author = {Xu, Depeng and Yuan, Shuhan and Wu, Xintao and Phan, {HaiNhat}},
	editor = {Phung, Dinh and Tseng, Vincent S. and Webb, Geoffrey I. and Ho, Bao and Ganji, Mohadeseh and Rashidi, Lida},
	date = {2018},
	langid = {english},
	file = {2018_DPNE_Xu et al.pdf:/home/sy/Zotero/storage/4L2JLTMJ/2018_DPNE_Xu et al.pdf:application/pdf}
}

@inproceedings{xu_fairgan:_2018,
	title = {{FairGAN}: Fairness-aware Generative Adversarial Networks},
	doi = {10.1109/BigData.2018.8622525},
	shorttitle = {{FairGAN}},
	abstract = {Fairness-aware learning is increasingly important in data mining. Discrimination prevention aims to prevent discrimination in the training data before it is used to conduct predictive analysis. In this paper, we focus on fair data generation that ensures the generated data is discrimination free. Inspired by generative adversarial networks ({GAN}), we present fairness-aware generative adversarial networks, called {FairGAN}, which are able to learn a generator producing fair data and also preserving good data utility. Compared with the naive fair data generation models, {FairGAN} further ensures the classifiers which are trained on generated data can achieve fair classification on real data. Experiments on a real dataset show the effectiveness of {FairGAN}.},
	eventtitle = {2018 {IEEE} International Conference on Big Data (Big Data)},
	pages = {570--575},
	booktitle = {2018 {IEEE} International Conference on Big Data (Big Data)},
	author = {Xu, D. and Yuan, S. and Zhang, L. and Wu, X.},
	date = {2018-12},
	keywords = {learning (artificial intelligence), Training, data mining, Training data, Data models, pattern classification, Predictive models, training data, Generators, data integrity, data utility, discrimination prevention, fair classification, {FairGAN}, fairness-aware generative adversarial networks, fairness-aware learning, Gallium nitride, Generative adversarial networks},
	file = {2018_FairGAN_Xu et al.pdf:/home/sy/Zotero/storage/9RWDLCNW/2018_FairGAN_Xu et al.pdf:application/pdf;IEEE Xplore Abstract Record:/home/sy/Zotero/storage/7L8HBCQ6/8622525.html:text/html}
}

@inproceedings{li_dynamic_2019,
	title = {Dynamic Anomaly Detection Using Vector Autoregressive Model},
	url = {https://doi.org/10.1007/978-3-030-16148-4_46},
	doi = {10.1007/978-3-030-16148-4_46},
	pages = {600--611},
	booktitle = {Advances in Knowledge Discovery and Data Mining - 23rd Pacific-Asia Conference, {PAKDD} 2019, Macau, China, April 14-17, 2019, Proceedings, Part I},
	author = {Li, Yuemeng and Lu, Aidong and Wu, Xintao and Yuan, Shuhan},
	date = {2019}
}

@inproceedings{xu_achieving_2019,
	location = {New York, {NY}, {USA}},
	title = {Achieving Differential Privacy and Fairness in Logistic Regression},
	isbn = {978-1-4503-6675-5},
	url = {http://doi.acm.org/10.1145/3308560.3317584},
	doi = {10.1145/3308560.3317584},
	series = {{WWW} '19},
	abstract = {Machine learning algorithms are used to make decisions in various applications. These algorithms rely on large amounts of sensitive individual information to work properly. Hence, there are sociological concerns about machine learning algorithms on matters like privacy and fairness. Currently, many studies focus on only protecting individual privacy or ensuring fairness of algorithms. However, how to meet both privacy and fairness requirements simultaneously in machine learning algorithms is under exploited. In this paper, we focus on one classic machine learning model, logistic regression, and develop differentially private and fair logistic regression models by combining functional mechanism and decision boundary fairness in a joint form. Theoretical analysis and empirical evaluations demonstrate our approaches effectively achieve both differential privacy and fairness while preserving good utility.},
	pages = {594--599},
	booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
	publisher = {{ACM}},
	author = {Xu, Depeng and Yuan, Shuhan and Wu, Xintao},
	urldate = {2019-07-26},
	date = {2019},
	note = {event-place: San Francisco, {USA}},
	keywords = {Differential Privacy, Fairness-aware Learning, Logistic Regression},
	file = {2019_Achieving Differential Privacy and Fairness in Logistic Regression_Xu et al.pdf:/home/sy/Zotero/storage/PGUA7XWD/2019_Achieving Differential Privacy and Fairness in Logistic Regression_Xu et al.pdf:application/pdf}
}

@inproceedings{zheng_one-class_2019,
	title = {One-Class Adversarial Nets for Fraud Detection},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/3924},
	pages = {1286--1293},
	booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI} 2019},
	author = {Zheng, Panpan and Yuan, Shuhan and Wu, Xintao and Li, Jun and Lu, Aidong},
	date = {2019}
}

@inproceedings{zheng_safe:_2019,
	title = {{SAFE}: A Neural Survival Analysis Model for Fraud Early Detection},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/3923},
	pages = {1278--1285},
	booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI} 2019},
	author = {Zheng, Panpan and Yuan, Shuhan and Wu, Xintao},
	date = {2019}
}